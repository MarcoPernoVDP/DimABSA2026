{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df61040b",
   "metadata": {},
   "source": [
    "## üì¶ Part 1: Setup and Installation\n",
    "\n",
    "Installing required libraries for transformer models, data processing, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers==4.36.0\n",
    "!pip install -q torch==2.1.0\n",
    "!pip install -q datasets==2.16.0\n",
    "!pip install -q scikit-learn==1.3.2\n",
    "!pip install -q pandas==2.1.4\n",
    "!pip install -q numpy==1.26.2\n",
    "!pip install -q matplotlib==3.8.2\n",
    "!pip install -q seaborn==0.13.0\n",
    "!pip install -q tqdm==4.66.1\n",
    "!pip install -q accelerate==0.25.0\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0cdb76",
   "metadata": {},
   "source": [
    "## üìö Part 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoConfig,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Device: {device}\")\n",
    "print(f\"üé≤ Random seed: {SEED}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üíª GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üìä Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e231bf",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Part 3: Configuration\n",
    "\n",
    "Define all hyperparameters and settings in a structured configuration class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13270f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration for DimASR task\"\"\"\n",
    "    \n",
    "    # Task Configuration\n",
    "    subtask: str = \"subtask_1\"\n",
    "    track: str = \"track_a\"\n",
    "    language: str = \"eng\"  # Options: eng, jpn, rus, tat, ukr, zho\n",
    "    domain: str = \"restaurant\"  # Options: restaurant, laptop, hotel, finance\n",
    "    \n",
    "    # Model Configuration\n",
    "    model_name: str = \"bert-base-multilingual-cased\"\n",
    "    # Alternative models to try:\n",
    "    # - \"xlm-roberta-base\"\n",
    "    # - \"microsoft/mdeberta-v3-base\"\n",
    "    # - \"bert-base-uncased\" (for English only)\n",
    "    # - \"roberta-base\" (for English only)\n",
    "    \n",
    "    # Training Hyperparameters\n",
    "    max_length: int = 128\n",
    "    batch_size: int = 16\n",
    "    learning_rate: float = 2e-5\n",
    "    weight_decay: float = 0.01\n",
    "    num_epochs: int = 5\n",
    "    warmup_ratio: float = 0.1\n",
    "    gradient_clip: float = 1.0\n",
    "    \n",
    "    # Data Split\n",
    "    val_split: float = 0.1\n",
    "    \n",
    "    # Output Configuration\n",
    "    output_dir: str = \"./outputs\"\n",
    "    save_best_model: bool = True\n",
    "    \n",
    "    # Advanced Settings\n",
    "    dropout_rate: float = 0.1\n",
    "    use_scheduler: bool = True\n",
    "    scheduler_type: str = \"linear\"  # Options: linear, cosine, plateau\n",
    "    \n",
    "    # VA score constraints\n",
    "    va_min: float = 1.0\n",
    "    va_max: float = 9.0\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Create output directory and build URLs\"\"\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        # Build data URLs\n",
    "        base_url = \"https://raw.githubusercontent.com/DimABSA/DimABSA2026/main/task-dataset\"\n",
    "        self.train_url = f\"{base_url}/{self.track}/{self.subtask}/{self.language}/{self.language}_{self.domain}_train_alltasks.jsonl\"\n",
    "        self.dev_url = f\"{base_url}/{self.track}/{self.subtask}/{self.language}/{self.language}_{self.domain}_dev_task1.jsonl\"\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display configuration\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"üîß CONFIGURATION\")\n",
    "        print(\"=\" * 60)\n",
    "        for key, value in self.__dict__.items():\n",
    "            if not key.endswith('_url'):\n",
    "                print(f\"{key:20s}: {value}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e44b59",
   "metadata": {},
   "source": [
    "## üìä Part 4: Data Loading and Processing\n",
    "\n",
    "Load JSONL data from GitHub and convert to structured DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_from_url(url: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load JSONL data from URL.\n",
    "    \n",
    "    Args:\n",
    "        url: URL to JSONL file\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries\n",
    "    \"\"\"\n",
    "    import urllib.request\n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            data = response.read().decode('utf-8')\n",
    "            return [json.loads(line) for line in data.strip().split('\\n') if line.strip()]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data from {url}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def jsonl_to_dataframe(data: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert JSONL data to pandas DataFrame.\n",
    "    \n",
    "    Handles different data formats:\n",
    "    - Quadruplet (Task 3): has 'Quadruplet' field\n",
    "    - Triplet (Task 2): has 'Triplet' field  \n",
    "    - Aspect_VA (Task 1 with labels): has 'Aspect_VA' field\n",
    "    - Aspect (Task 1 without labels): has 'Aspect' field\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries from JSONL\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: ID, Text, Aspect, Valence, Arousal\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        raise ValueError(\"Empty data list\")\n",
    "    \n",
    "    first_item = data[0]\n",
    "    \n",
    "    # Quadruplet format (Task 3)\n",
    "    if 'Quadruplet' in first_item:\n",
    "        df = pd.json_normalize(data, 'Quadruplet', ['ID', 'Text'])\n",
    "        df[['Valence', 'Arousal']] = df['VA'].str.split('#', expand=True).astype(float)\n",
    "        df = df.drop(columns=['VA', 'Category', 'Opinion'], errors='ignore')\n",
    "        \n",
    "    # Triplet format (Task 2)\n",
    "    elif 'Triplet' in first_item:\n",
    "        df = pd.json_normalize(data, 'Triplet', ['ID', 'Text'])\n",
    "        df[['Valence', 'Arousal']] = df['VA'].str.split('#', expand=True).astype(float)\n",
    "        df = df.drop(columns=['VA', 'Opinion'], errors='ignore')\n",
    "        \n",
    "    # Aspect_VA format (Task 1 with labels)\n",
    "    elif 'Aspect_VA' in first_item:\n",
    "        df = pd.json_normalize(data, 'Aspect_VA', ['ID', 'Text'])\n",
    "        df = df.rename(columns={df.columns[0]: 'Aspect'})\n",
    "        df[['Valence', 'Arousal']] = df['VA'].str.split('#', expand=True).astype(float)\n",
    "        df = df.drop(columns=['VA'], errors='ignore')\n",
    "        \n",
    "    # Aspect format (Task 1 without labels - test set)\n",
    "    elif 'Aspect' in first_item:\n",
    "        df = pd.json_normalize(data, 'Aspect', ['ID', 'Text'])\n",
    "        df = df.rename(columns={df.columns[0]: 'Aspect'})\n",
    "        df['Valence'] = 0.0  # Placeholder\n",
    "        df['Arousal'] = 0.0  # Placeholder\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unknown data format. Expected 'Quadruplet', 'Triplet', 'Aspect_VA', or 'Aspect'\")\n",
    "    \n",
    "    # Remove duplicates (same ID + Aspect)\n",
    "    df = df.drop_duplicates(subset=['ID', 'Aspect'], keep='first')\n",
    "    \n",
    "    # Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def load_and_process_data(config: Config) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load and split data into train/val/test.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration object\n",
    "        \n",
    "    Returns:\n",
    "        train_df, val_df, test_df\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üì• LOADING DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load training data\n",
    "    print(f\"Loading training data from: {config.train_url}\")\n",
    "    train_raw = load_jsonl_from_url(config.train_url)\n",
    "    train_df = jsonl_to_dataframe(train_raw)\n",
    "    print(f\"‚úÖ Training data loaded: {len(train_df)} samples\")\n",
    "    \n",
    "    # Load test data (dev set for evaluation)\n",
    "    print(f\"\\nLoading test data from: {config.dev_url}\")\n",
    "    test_raw = load_jsonl_from_url(config.dev_url)\n",
    "    test_df = jsonl_to_dataframe(test_raw)\n",
    "    print(f\"‚úÖ Test data loaded: {len(test_df)} samples\")\n",
    "    \n",
    "    # Split training data into train/val\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_df,\n",
    "        test_size=config.val_split,\n",
    "        random_state=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Data Split:\")\n",
    "    print(f\"  - Train: {len(train_df)} samples\")\n",
    "    print(f\"  - Val:   {len(val_df)} samples\")\n",
    "    print(f\"  - Test:  {len(test_df)} samples\")\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_df, val_df, test_df = load_and_process_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f9e8e",
   "metadata": {},
   "source": [
    "## üîç Part 5: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Analyze the data distribution, VA scores, and aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df: pd.DataFrame, title: str = \"Dataset\"):\n",
    "    \"\"\"\n",
    "    Perform exploratory data analysis.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to analyze\n",
    "        title: Title for plots\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"üìà EDA: {title}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nüìä Shape: {df.shape}\")\n",
    "    print(f\"\\nüìã Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\n‚ùì Missing values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # VA statistics\n",
    "    if 'Valence' in df.columns and df['Valence'].sum() > 0:\n",
    "        print(f\"\\nüìâ Valence statistics:\")\n",
    "        print(df['Valence'].describe())\n",
    "        \n",
    "        print(f\"\\nüìâ Arousal statistics:\")\n",
    "        print(df['Arousal'].describe())\n",
    "        \n",
    "        # Text length\n",
    "        df['text_length'] = df['Text'].str.len()\n",
    "        df['word_count'] = df['Text'].str.split().str.len()\n",
    "        \n",
    "        print(f\"\\nüìè Text length statistics:\")\n",
    "        print(df['text_length'].describe())\n",
    "        \n",
    "        print(f\"\\nüìù Word count statistics:\")\n",
    "        print(df['word_count'].describe())\n",
    "        \n",
    "        # Sample data\n",
    "        print(f\"\\nüî¨ Sample data:\")\n",
    "        print(df[['Text', 'Aspect', 'Valence', 'Arousal']].head(3))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Perform EDA on all datasets\n",
    "train_df = perform_eda(train_df, \"Training Set\")\n",
    "val_df = perform_eda(val_df, \"Validation Set\")\n",
    "test_df = perform_eda(test_df, \"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05199365",
   "metadata": {},
   "source": [
    "## üìä Part 6: Data Visualization\n",
    "\n",
    "Visualize VA score distributions and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_va_distribution(df: pd.DataFrame, title: str = \"Dataset\"):\n",
    "    \"\"\"\n",
    "    Visualize Valence-Arousal distribution.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with Valence and Arousal columns\n",
    "        title: Title for the plot\n",
    "    \"\"\"\n",
    "    if 'Valence' not in df.columns or df['Valence'].sum() == 0:\n",
    "        print(f\"‚ö†Ô∏è Skipping visualization for {title} (no VA labels)\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f'{title} - VA Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Valence distribution\n",
    "    axes[0, 0].hist(df['Valence'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(df['Valence'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"Valence\"].mean():.2f}')\n",
    "    axes[0, 0].set_xlabel('Valence', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 0].set_title('Valence Distribution', fontsize=14)\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Arousal distribution\n",
    "    axes[0, 1].hist(df['Arousal'], bins=30, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].axvline(df['Arousal'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"Arousal\"].mean():.2f}')\n",
    "    axes[0, 1].set_xlabel('Arousal', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 1].set_title('Arousal Distribution', fontsize=14)\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. VA scatter plot\n",
    "    scatter = axes[1, 0].scatter(df['Valence'], df['Arousal'], alpha=0.5, c=df['Valence'], cmap='RdYlGn', s=30)\n",
    "    axes[1, 0].set_xlabel('Valence', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Arousal', fontsize=12)\n",
    "    axes[1, 0].set_title('Valence-Arousal Space', fontsize=14)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=axes[1, 0], label='Valence')\n",
    "    \n",
    "    # Add quadrants\n",
    "    v_mean, a_mean = df['Valence'].mean(), df['Arousal'].mean()\n",
    "    axes[1, 0].axvline(v_mean, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[1, 0].axhline(a_mean, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 4. Correlation heatmap\n",
    "    if 'text_length' in df.columns:\n",
    "        corr_data = df[['Valence', 'Arousal', 'text_length', 'word_count']].corr()\n",
    "        sns.heatmap(corr_data, annot=True, fmt='.3f', cmap='coolwarm', center=0, \n",
    "                   ax=axes[1, 1], square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "        axes[1, 1].set_title('Feature Correlations', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nüìä {title} VA Statistics:\")\n",
    "    print(f\"  Valence: {df['Valence'].min():.2f} - {df['Valence'].max():.2f} (mean: {df['Valence'].mean():.2f})\")\n",
    "    print(f\"  Arousal: {df['Arousal'].min():.2f} - {df['Arousal'].max():.2f} (mean: {df['Arousal'].mean():.2f})\")\n",
    "    print(f\"  Correlation (V-A): {df['Valence'].corr(df['Arousal']):.3f}\")\n",
    "\n",
    "\n",
    "# Visualize training data\n",
    "visualize_va_distribution(train_df, \"Training Set\")\n",
    "visualize_va_distribution(val_df, \"Validation Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba59344",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Part 7: Dataset Class\n",
    "\n",
    "Create custom PyTorch Dataset for VA regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VADataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for Valence-Arousal regression.\n",
    "    \n",
    "    Combines aspect and text into a single input string:\n",
    "    Format: \"[ASPECT] aspect_term [SEP] text\"\n",
    "    \n",
    "    Args:\n",
    "        dataframe: DataFrame with columns [Text, Aspect, Valence, Arousal]\n",
    "        tokenizer: HuggingFace tokenizer\n",
    "        max_length: Maximum sequence length\n",
    "        is_test: Whether this is test data (no labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        tokenizer,\n",
    "        max_length: int = 128,\n",
    "        is_test: bool = False\n",
    "    ):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Get a single sample.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with:\n",
    "            - input_ids: Token IDs\n",
    "            - attention_mask: Attention mask\n",
    "            - labels: [Valence, Arousal] (if not test)\n",
    "        \"\"\"\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Construct input text\n",
    "        aspect = str(row['Aspect'])\n",
    "        text = str(row['Text'])\n",
    "        \n",
    "        # Format: \"[ASPECT] aspect [SEP] text\"\n",
    "        input_text = f\"[ASPECT] {aspect} [SEP] {text}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0)\n",
    "        }\n",
    "        \n",
    "        # Add labels if not test\n",
    "        if not self.is_test:\n",
    "            valence = float(row['Valence'])\n",
    "            arousal = float(row['Arousal'])\n",
    "            item['labels'] = torch.tensor([valence, arousal], dtype=torch.float32)\n",
    "        \n",
    "        return item\n",
    "\n",
    "\n",
    "# Initialize tokenizer\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üî§ INITIALIZING TOKENIZER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "print(f\"‚úÖ Tokenizer loaded: {config.model_name}\")\n",
    "print(f\"üìè Vocab size: {tokenizer.vocab_size}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = VADataset(train_df, tokenizer, config.max_length, is_test=False)\n",
    "val_dataset = VADataset(val_df, tokenizer, config.max_length, is_test=False)\n",
    "test_dataset = VADataset(test_df, tokenizer, config.max_length, is_test=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets created:\")\n",
    "print(f\"  - Train: {len(train_dataset)} samples\")\n",
    "print(f\"  - Val:   {len(val_dataset)} samples\")\n",
    "print(f\"  - Test:  {len(test_dataset)} samples\")\n",
    "\n",
    "# Test dataset\n",
    "print(f\"\\nüî¨ Sample from training dataset:\")\n",
    "sample = train_dataset[0]\n",
    "print(f\"  Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"  Attention mask shape: {sample['attention_mask'].shape}\")\n",
    "if 'labels' in sample:\n",
    "    print(f\"  Labels: {sample['labels']}\")\n",
    "print(f\"  Decoded text: {tokenizer.decode(sample['input_ids'], skip_special_tokens=True)[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5984f83",
   "metadata": {},
   "source": [
    "## üîß Part 8: DataLoader Creation\n",
    "\n",
    "Create efficient DataLoaders for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f391df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üì¶ DATALOADERS CREATED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches:   {len(val_loader)}\")\n",
    "print(f\"Test batches:  {len(test_loader)}\")\n",
    "\n",
    "# Test a batch\n",
    "print(f\"\\nüî¨ Sample batch:\")\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"  Input IDs shape: {batch['input_ids'].shape}\")\n",
    "print(f\"  Attention mask shape: {batch['attention_mask'].shape}\")\n",
    "print(f\"  Labels shape: {batch['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfaf109",
   "metadata": {},
   "source": [
    "## üß† Part 9: Model Architecture\n",
    "\n",
    "Define a sophisticated VA regression model with:\n",
    "- Pretrained transformer backbone\n",
    "- Multi-layer regression head\n",
    "- Dropout regularization\n",
    "- Output clamping to [1, 9] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VARegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Valence-Arousal Regressor based on pretrained transformers.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Pretrained transformer (BERT, RoBERTa, XLM-R, etc.)\n",
    "    2. Dropout for regularization\n",
    "    3. Multi-layer feedforward network\n",
    "    4. Two output heads: one for Valence, one for Arousal\n",
    "    5. Output clamping to [1, 9] range\n",
    "    \n",
    "    Args:\n",
    "        model_name: HuggingFace model name\n",
    "        dropout_rate: Dropout probability\n",
    "        va_min: Minimum VA value (default: 1.0)\n",
    "        va_max: Maximum VA value (default: 9.0)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        dropout_rate: float = 0.1,\n",
    "        va_min: float = 1.0,\n",
    "        va_max: float = 9.0\n",
    "    ):\n",
    "        super(VARegressor, self).__init__()\n",
    "        \n",
    "        self.va_min = va_min\n",
    "        self.va_max = va_max\n",
    "        \n",
    "        # Load pretrained transformer\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        hidden_size = self.config.hidden_size\n",
    "        \n",
    "        # Regression head\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Two-layer feedforward network\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Separate heads for Valence and Arousal\n",
    "        self.valence_head = nn.Linear(hidden_size // 2, 1)\n",
    "        self.arousal_head = nn.Linear(hidden_size // 2, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize regression head weights\"\"\"\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.xavier_uniform_(self.valence_head.weight)\n",
    "        nn.init.zeros_(self.valence_head.bias)\n",
    "        nn.init.xavier_uniform_(self.arousal_head.weight)\n",
    "        nn.init.zeros_(self.arousal_head.bias)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token IDs [batch_size, seq_len]\n",
    "            attention_mask: Attention mask [batch_size, seq_len]\n",
    "            \n",
    "        Returns:\n",
    "            Predictions [batch_size, 2] where [:, 0] is Valence and [:, 1] is Arousal\n",
    "        \"\"\"\n",
    "        # Get transformer outputs\n",
    "        outputs = self.transformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        # Apply dropout\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Feedforward network\n",
    "        hidden = self.fc1(pooled_output)\n",
    "        hidden = self.activation(hidden)\n",
    "        hidden = self.dropout2(hidden)\n",
    "        \n",
    "        # Separate predictions\n",
    "        valence = self.valence_head(hidden)  # [batch_size, 1]\n",
    "        arousal = self.arousal_head(hidden)  # [batch_size, 1]\n",
    "        \n",
    "        # Concatenate and clamp to [va_min, va_max]\n",
    "        predictions = torch.cat([valence, arousal], dim=1)  # [batch_size, 2]\n",
    "        predictions = torch.clamp(predictions, self.va_min, self.va_max)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üß† INITIALIZING MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model = VARegressor(\n",
    "    model_name=config.model_name,\n",
    "    dropout_rate=config.dropout_rate,\n",
    "    va_min=config.va_min,\n",
    "    va_max=config.va_max\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"‚úÖ Model: {config.model_name}\")\n",
    "print(f\"üìä Total parameters: {total_params:,}\")\n",
    "print(f\"üéØ Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"üíæ Model size: {total_params * 4 / 1e6:.2f} MB\")\n",
    "\n",
    "# Test forward pass\n",
    "print(f\"\\nüî¨ Testing forward pass...\")\n",
    "batch = next(iter(train_loader))\n",
    "input_ids = batch['input_ids'].to(device)\n",
    "attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    print(f\"‚úÖ Output shape: {outputs.shape}\")\n",
    "    print(f\"‚úÖ Sample predictions: {outputs[0].cpu().numpy()}\")\n",
    "    print(f\"‚úÖ Value range: [{outputs.min():.2f}, {outputs.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a365c",
   "metadata": {},
   "source": [
    "## üìê Part 10: Loss Function and Metrics\n",
    "\n",
    "Define custom loss function and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VALoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom loss function for VA regression.\n",
    "    \n",
    "    Combines MSE loss for Valence and Arousal with optional weighting.\n",
    "    \n",
    "    Args:\n",
    "        valence_weight: Weight for valence loss (default: 1.0)\n",
    "        arousal_weight: Weight for arousal loss (default: 1.0)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, valence_weight: float = 1.0, arousal_weight: float = 1.0):\n",
    "        super(VALoss, self).__init__()\n",
    "        self.valence_weight = valence_weight\n",
    "        self.arousal_weight = arousal_weight\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute loss.\n",
    "        \n",
    "        Args:\n",
    "            predictions: Predicted VA scores [batch_size, 2]\n",
    "            targets: True VA scores [batch_size, 2]\n",
    "            \n",
    "        Returns:\n",
    "            Scalar loss value\n",
    "        \"\"\"\n",
    "        valence_loss = self.mse(predictions[:, 0], targets[:, 0])\n",
    "        arousal_loss = self.mse(predictions[:, 1], targets[:, 1])\n",
    "        \n",
    "        total_loss = (\n",
    "            self.valence_weight * valence_loss +\n",
    "            self.arousal_weight * arousal_loss\n",
    "        )\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "def compute_rmse(predictions: np.ndarray, targets: np.ndarray) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Compute RMSE for VA prediction.\n",
    "    \n",
    "    RMSE_VA = sqrt(sum((V_pred - V_true)^2 + (A_pred - A_true)^2) / N)\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted VA scores [N, 2]\n",
    "        targets: True VA scores [N, 2]\n",
    "        \n",
    "    Returns:\n",
    "        rmse_combined: Combined RMSE for both V and A\n",
    "        rmse_valence: RMSE for Valence only\n",
    "        rmse_arousal: RMSE for Arousal only\n",
    "    \"\"\"\n",
    "    # Separate valence and arousal\n",
    "    v_pred, a_pred = predictions[:, 0], predictions[:, 1]\n",
    "    v_true, a_true = targets[:, 0], targets[:, 1]\n",
    "    \n",
    "    # Compute RMSE for each\n",
    "    rmse_valence = np.sqrt(mean_squared_error(v_true, v_pred))\n",
    "    rmse_arousal = np.sqrt(mean_squared_error(a_true, a_pred))\n",
    "    \n",
    "    # Combined RMSE (official metric)\n",
    "    squared_errors = (v_pred - v_true) ** 2 + (a_pred - a_true) ** 2\n",
    "    rmse_combined = np.sqrt(np.mean(squared_errors))\n",
    "    \n",
    "    return rmse_combined, rmse_valence, rmse_arousal\n",
    "\n",
    "\n",
    "# Initialize loss function\n",
    "criterion = VALoss(valence_weight=1.0, arousal_weight=1.0)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìê LOSS FUNCTION AND METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úÖ Loss: Custom VA Loss (MSE-based)\")\n",
    "print(f\"‚úÖ Metric: RMSE_VA = sqrt(sum((V_p - V_t)^2 + (A_p - A_t)^2) / N)\")\n",
    "\n",
    "# Test loss computation\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(train_loader))\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    \n",
    "    predictions = model(input_ids, attention_mask)\n",
    "    loss = criterion(predictions, labels)\n",
    "    \n",
    "    print(f\"\\nüî¨ Test loss computation:\")\n",
    "    print(f\"  Loss value: {loss.item():.4f}\")\n",
    "    \n",
    "    # Test RMSE\n",
    "    pred_np = predictions.cpu().numpy()\n",
    "    label_np = labels.cpu().numpy()\n",
    "    rmse_combined, rmse_v, rmse_a = compute_rmse(pred_np, label_np)\n",
    "    \n",
    "    print(f\"  RMSE (combined): {rmse_combined:.4f}\")\n",
    "    print(f\"  RMSE (valence):  {rmse_v:.4f}\")\n",
    "    print(f\"  RMSE (arousal):  {rmse_a:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5010e1f9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Part 1 Complete!\n",
    "\n",
    "**Summary of Part 1:**\n",
    "1. ‚úÖ Setup and installation\n",
    "2. ‚úÖ Data loading and preprocessing\n",
    "3. ‚úÖ Exploratory data analysis\n",
    "4. ‚úÖ Dataset and DataLoader creation\n",
    "5. ‚úÖ Model architecture definition\n",
    "6. ‚úÖ Loss function and metrics\n",
    "\n",
    "**Next Steps (Part 2):**\n",
    "- Optimizer and scheduler setup\n",
    "- Training loop with progress tracking\n",
    "- Validation and evaluation\n",
    "- Model checkpointing\n",
    "- Prediction generation\n",
    "- Submission file creation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8246c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üöÄ PART 2: Training, Evaluation & Submission\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Part 11: Optimizer and Scheduler Setup\n",
    "\n",
    "Configure optimizer with weight decay and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34138dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer with layer-wise learning rate decay (optional)\n",
    "# Separate parameters: transformer backbone vs regression head\n",
    "no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in model.transformer.named_parameters() \n",
    "                   if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': config.weight_decay,\n",
    "        'lr': config.learning_rate\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.transformer.named_parameters() \n",
    "                   if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "        'lr': config.learning_rate\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() \n",
    "                   if 'transformer' not in n and not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': config.weight_decay,\n",
    "        'lr': config.learning_rate * 10  # Higher LR for regression head\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() \n",
    "                   if 'transformer' not in n and any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0,\n",
    "        'lr': config.learning_rate * 10\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, eps=1e-8)\n",
    "\n",
    "# Calculate total training steps\n",
    "total_steps = len(train_loader) * config.num_epochs\n",
    "warmup_steps = int(total_steps * config.warmup_ratio)\n",
    "\n",
    "# Create scheduler\n",
    "if config.use_scheduler:\n",
    "    if config.scheduler_type == 'linear':\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "    elif config.scheduler_type == 'cosine':\n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=total_steps,\n",
    "            eta_min=1e-7\n",
    "        )\n",
    "    elif config.scheduler_type == 'plateau':\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            verbose=True\n",
    "        )\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîß OPTIMIZER AND SCHEDULER\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úÖ Optimizer: AdamW\")\n",
    "print(f\"  - Learning rate: {config.learning_rate}\")\n",
    "print(f\"  - Weight decay: {config.weight_decay}\")\n",
    "print(f\"  - Regression head LR: {config.learning_rate * 10}\")\n",
    "print(f\"\\n‚úÖ Scheduler: {config.scheduler_type if config.use_scheduler else 'None'}\")\n",
    "print(f\"  - Total steps: {total_steps}\")\n",
    "print(f\"  - Warmup steps: {warmup_steps}\")\n",
    "print(f\"  - Warmup ratio: {config.warmup_ratio}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72aafb",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Part 12: Training and Validation Functions\n",
    "\n",
    "Define comprehensive training and validation functions with progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50429e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: Optional[object],\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    gradient_clip: float = 1.0\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Train for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: VA regression model\n",
    "        dataloader: Training data loader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        scheduler: Learning rate scheduler\n",
    "        device: Device to train on\n",
    "        epoch: Current epoch number\n",
    "        gradient_clip: Max gradient norm\n",
    "        \n",
    "    Returns:\n",
    "        avg_loss, rmse_combined, rmse_valence, rmse_arousal\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch}\", leave=False)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        # Move to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(input_ids, attention_mask)\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Scheduler step (if not plateau)\n",
    "        if scheduler is not None and config.scheduler_type != 'plateau':\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Accumulate metrics\n",
    "        total_loss += loss.item()\n",
    "        all_predictions.append(predictions.detach().cpu().numpy())\n",
    "        all_targets.append(labels.detach().cpu().numpy())\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'lr': f'{optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "        })\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    \n",
    "    rmse_combined, rmse_valence, rmse_arousal = compute_rmse(all_predictions, all_targets)\n",
    "    \n",
    "    return avg_loss, rmse_combined, rmse_valence, rmse_arousal\n",
    "\n",
    "\n",
    "def validate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float, float, float, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Validate the model.\n",
    "    \n",
    "    Args:\n",
    "        model: VA regression model\n",
    "        dataloader: Validation data loader\n",
    "        criterion: Loss function\n",
    "        device: Device to validate on\n",
    "        \n",
    "    Returns:\n",
    "        avg_loss, rmse_combined, rmse_valence, rmse_arousal, predictions, targets\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Validating\", leave=False):\n",
    "            # Move to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(input_ids, attention_mask)\n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    \n",
    "    rmse_combined, rmse_valence, rmse_arousal = compute_rmse(all_predictions, all_targets)\n",
    "    \n",
    "    return avg_loss, rmse_combined, rmse_valence, rmse_arousal, all_predictions, all_targets\n",
    "\n",
    "\n",
    "print(\"\\n‚úÖ Training and validation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31573744",
   "metadata": {},
   "source": [
    "## üéØ Part 13: Main Training Loop\n",
    "\n",
    "Execute the complete training process with checkpointing and early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history tracking\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_rmse': [],\n",
    "    'train_rmse_v': [],\n",
    "    'train_rmse_a': [],\n",
    "    'val_loss': [],\n",
    "    'val_rmse': [],\n",
    "    'val_rmse_v': [],\n",
    "    'val_rmse_a': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "best_val_rmse = float('inf')\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "early_stop_patience = 3\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total epochs: {config.num_epochs}\")\n",
    "print(f\"Train batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, config.num_epochs + 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìç EPOCH {epoch}/{config.num_epochs}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss, train_rmse, train_rmse_v, train_rmse_a = train_epoch(\n",
    "        model=model,\n",
    "        dataloader=train_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        epoch=epoch,\n",
    "        gradient_clip=config.gradient_clip\n",
    "    )\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_rmse, val_rmse_v, val_rmse_a, val_preds, val_targets = validate(\n",
    "        model=model,\n",
    "        dataloader=val_loader,\n",
    "        criterion=criterion,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Learning rate (get first param group)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update scheduler (if plateau)\n",
    "    if scheduler is not None and config.scheduler_type == 'plateau':\n",
    "        scheduler.step(val_rmse)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_rmse'].append(train_rmse)\n",
    "    history['train_rmse_v'].append(train_rmse_v)\n",
    "    history['train_rmse_a'].append(train_rmse_a)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_rmse'].append(val_rmse)\n",
    "    history['val_rmse_v'].append(val_rmse_v)\n",
    "    history['val_rmse_a'].append(val_rmse_a)\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nüìä Results:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train RMSE: {train_rmse:.4f} (V: {train_rmse_v:.4f}, A: {train_rmse_a:.4f})\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val RMSE:   {val_rmse:.4f} (V: {val_rmse_v:.4f}, A: {val_rmse_a:.4f})\")\n",
    "    print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "    \n",
    "    # Check for best model\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_epoch = epoch\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save best model\n",
    "        if config.save_best_model:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_rmse': val_rmse,\n",
    "                'config': config\n",
    "            }\n",
    "            checkpoint_path = os.path.join(config.output_dir, 'best_model.pt')\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            print(f\"\\n‚úÖ New best model saved! RMSE: {val_rmse:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"\\n‚ö†Ô∏è No improvement ({patience_counter}/{early_stop_patience})\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"\\nüõë Early stopping triggered at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ TRAINING COMPLETED!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best validation RMSE: {best_val_rmse:.4f} (epoch {best_epoch})\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b4c09",
   "metadata": {},
   "source": [
    "## üìà Part 14: Training History Visualization\n",
    "\n",
    "Visualize training progress and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history: Dict):\n",
    "    \"\"\"Plot training history.\"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Training History', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Loss curves\n",
    "    axes[0, 0].plot(epochs, history['train_loss'], 'b-o', label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(epochs, history['val_loss'], 'r-o', label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0, 0].set_title('Loss Curves', fontsize=14)\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. RMSE curves\n",
    "    axes[0, 1].plot(epochs, history['train_rmse'], 'b-o', label='Train RMSE', linewidth=2)\n",
    "    axes[0, 1].plot(epochs, history['val_rmse'], 'r-o', label='Val RMSE', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('RMSE', fontsize=12)\n",
    "    axes[0, 1].set_title('RMSE Curves (Combined)', fontsize=14)\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].axhline(y=min(history['val_rmse']), color='g', linestyle='--', \n",
    "                       label=f'Best: {min(history[\"val_rmse\"]):.4f}', alpha=0.5)\n",
    "    \n",
    "    # 3. Valence vs Arousal RMSE\n",
    "    axes[1, 0].plot(epochs, history['val_rmse_v'], 'g-o', label='Valence RMSE', linewidth=2)\n",
    "    axes[1, 0].plot(epochs, history['val_rmse_a'], 'm-o', label='Arousal RMSE', linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('RMSE', fontsize=12)\n",
    "    axes[1, 0].set_title('Validation RMSE by Dimension', fontsize=14)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Learning rate\n",
    "    axes[1, 1].plot(epochs, history['learning_rates'], 'c-o', linewidth=2)\n",
    "    axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[1, 1].set_title('Learning Rate Schedule', fontsize=14)\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä TRAINING SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Best Validation RMSE: {min(history['val_rmse']):.4f} (Epoch {np.argmin(history['val_rmse']) + 1})\")\n",
    "    print(f\"Final Train RMSE: {history['train_rmse'][-1]:.4f}\")\n",
    "    print(f\"Final Val RMSE: {history['val_rmse'][-1]:.4f}\")\n",
    "    print(f\"Improvement: {(history['val_rmse'][0] - min(history['val_rmse'])):.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5de6b",
   "metadata": {},
   "source": [
    "## üîÑ Part 15: Load Best Model\n",
    "\n",
    "Reload the best saved model for final evaluation and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49129af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model checkpoint\n",
    "checkpoint_path = os.path.join(config.output_dir, 'best_model.pt')\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üîÑ LOADING BEST MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"‚úÖ Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "    print(f\"‚úÖ Best validation RMSE: {checkpoint['val_rmse']:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No checkpoint found, using current model state\")\n",
    "\n",
    "# Re-evaluate on validation set\n",
    "print(\"\\nüîç Re-evaluating on validation set...\")\n",
    "val_loss, val_rmse, val_rmse_v, val_rmse_a, val_preds, val_targets = validate(\n",
    "    model=model,\n",
    "    dataloader=val_loader,\n",
    "    criterion=criterion,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Final Validation Results:\")\n",
    "print(f\"  Loss: {val_loss:.4f}\")\n",
    "print(f\"  RMSE (combined): {val_rmse:.4f}\")\n",
    "print(f\"  RMSE (valence):  {val_rmse_v:.4f}\")\n",
    "print(f\"  RMSE (arousal):  {val_rmse_a:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a90d1f",
   "metadata": {},
   "source": [
    "## üîÆ Part 16: Prediction on Test Set\n",
    "\n",
    "Generate predictions for the test set (dev data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3345fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate predictions.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        dataloader: Data loader\n",
    "        device: Device to use\n",
    "        \n",
    "    Returns:\n",
    "        Predictions array [N, 2]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            predictions = model(input_ids, attention_mask)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "\n",
    "# Generate predictions on test set\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîÆ GENERATING PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_predictions = predict(model, test_loader, device)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(test_predictions)} predictions\")\n",
    "print(f\"‚úÖ Predictions shape: {test_predictions.shape}\")\n",
    "print(f\"\\nüìä Prediction statistics:\")\n",
    "print(f\"  Valence: [{test_predictions[:, 0].min():.2f}, {test_predictions[:, 0].max():.2f}] (mean: {test_predictions[:, 0].mean():.2f})\")\n",
    "print(f\"  Arousal: [{test_predictions[:, 1].min():.2f}, {test_predictions[:, 1].max():.2f}] (mean: {test_predictions[:, 1].mean():.2f})\")\n",
    "\n",
    "# Show some sample predictions\n",
    "print(f\"\\nüî¨ Sample predictions:\")\n",
    "sample_df = test_df.copy()\n",
    "sample_df['Pred_Valence'] = test_predictions[:, 0]\n",
    "sample_df['Pred_Arousal'] = test_predictions[:, 1]\n",
    "sample_df['Pred_VA'] = sample_df.apply(\n",
    "    lambda row: f\"{row['Pred_Valence']:.2f}#{row['Pred_Arousal']:.2f}\", \n",
    "    axis=1\n",
    ")\n",
    "print(sample_df[['ID', 'Text', 'Aspect', 'Pred_VA']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe8104",
   "metadata": {},
   "source": [
    "## üìù Part 17: Create Submission File\n",
    "\n",
    "Format predictions according to competition requirements and save to JSONL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f1032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(\n",
    "    test_df: pd.DataFrame,\n",
    "    predictions: np.ndarray,\n",
    "    output_path: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create submission file in required JSONL format.\n",
    "    \n",
    "    Required format for Subtask 1:\n",
    "    {\n",
    "        \"ID\": \"unique_id\",\n",
    "        \"Aspect_VA\": [\n",
    "            {\"Aspect\": \"aspect_name\", \"VA\": \"V#A\"},\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    Args:\n",
    "        test_df: Test DataFrame with ID, Text, Aspect\n",
    "        predictions: Predictions array [N, 2]\n",
    "        output_path: Path to save submission file\n",
    "    \"\"\"\n",
    "    # Round predictions to 2 decimal places\n",
    "    valence = np.round(predictions[:, 0], 2)\n",
    "    arousal = np.round(predictions[:, 1])\n",
    "    \n",
    "    # Create VA strings\n",
    "    va_strings = [f\"{v:.2f}#{a:.2f}\" for v, a in zip(valence, arousal)]\n",
    "    \n",
    "    # Add predictions to dataframe\n",
    "    test_df_copy = test_df.copy()\n",
    "    test_df_copy['VA'] = va_strings\n",
    "    \n",
    "    # Group by ID to create the required format\n",
    "    submission = []\n",
    "    \n",
    "    for idx, group in test_df_copy.groupby('ID', sort=False):\n",
    "        aspect_va_list = []\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            aspect_va_list.append({\n",
    "                \"Aspect\": row['Aspect'],\n",
    "                \"VA\": row['VA']\n",
    "            })\n",
    "        \n",
    "        submission.append({\n",
    "            \"ID\": idx,\n",
    "            \"Aspect_VA\": aspect_va_list\n",
    "        })\n",
    "    \n",
    "    # Save to JSONL\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for item in submission:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"‚úÖ Submission file created: {output_path}\")\n",
    "    print(f\"‚úÖ Total entries: {len(submission)}\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "\n",
    "# Create submission file\n",
    "submission_filename = f\"pred_{config.language}_{config.domain}.jsonl\"\n",
    "submission_path = os.path.join(config.output_dir, submission_filename)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù CREATING SUBMISSION FILE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "submission_data = create_submission_file(\n",
    "    test_df=test_df,\n",
    "    predictions=test_predictions,\n",
    "    output_path=submission_path\n",
    ")\n",
    "\n",
    "# Display sample submissions\n",
    "print(f\"\\nüî¨ Sample submission entries:\")\n",
    "for i, entry in enumerate(submission_data[:3]):\n",
    "    print(f\"\\n{i+1}. ID: {entry['ID']}\")\n",
    "    for aspect_va in entry['Aspect_VA']:\n",
    "        print(f\"   - Aspect: {aspect_va['Aspect']}, VA: {aspect_va['VA']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"‚úÖ Submission file ready: {submission_path}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20c5e4",
   "metadata": {},
   "source": [
    "## üìä Part 18: Error Analysis\n",
    "\n",
    "Analyze prediction errors to understand model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_predictions(\n",
    "    df: pd.DataFrame,\n",
    "    predictions: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    title: str = \"Error Analysis\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze prediction errors.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with metadata\n",
    "        predictions: Predicted VA scores [N, 2]\n",
    "        targets: True VA scores [N, 2]\n",
    "        title: Title for the analysis\n",
    "    \"\"\"\n",
    "    # Calculate errors\n",
    "    v_errors = predictions[:, 0] - targets[:, 0]\n",
    "    a_errors = predictions[:, 1] - targets[:, 1]\n",
    "    euclidean_errors = np.sqrt((predictions[:, 0] - targets[:, 0])**2 + \n",
    "                               (predictions[:, 1] - targets[:, 1])**2)\n",
    "    \n",
    "    # Create error dataframe\n",
    "    error_df = df.copy()\n",
    "    error_df['Pred_V'] = predictions[:, 0]\n",
    "    error_df['Pred_A'] = predictions[:, 1]\n",
    "    error_df['True_V'] = targets[:, 0]\n",
    "    error_df['True_A'] = targets[:, 1]\n",
    "    error_df['Error_V'] = v_errors\n",
    "    error_df['Error_A'] = a_errors\n",
    "    error_df['Error_Euclidean'] = euclidean_errors\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"üìä {title.upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Error statistics\n",
    "    print(f\"\\nüìâ Error Statistics:\")\n",
    "    print(f\"  Valence MAE:  {np.abs(v_errors).mean():.4f}\")\n",
    "    print(f\"  Arousal MAE:  {np.abs(a_errors).mean():.4f}\")\n",
    "    print(f\"  Euclidean:    {euclidean_errors.mean():.4f}\")\n",
    "    \n",
    "    # Top errors\n",
    "    print(f\"\\nüî¥ Top 5 Worst Predictions (by Euclidean distance):\")\n",
    "    worst_indices = np.argsort(euclidean_errors)[-5:][::-1]\n",
    "    \n",
    "    for i, idx in enumerate(worst_indices, 1):\n",
    "        row = error_df.iloc[idx]\n",
    "        print(f\"\\n{i}. Error: {row['Error_Euclidean']:.4f}\")\n",
    "        print(f\"   Text: {row['Text'][:80]}...\")\n",
    "        print(f\"   Aspect: {row['Aspect']}\")\n",
    "        print(f\"   Predicted: V={row['Pred_V']:.2f}, A={row['Pred_A']:.2f}\")\n",
    "        print(f\"   True:      V={row['True_V']:.2f}, A={row['True_A']:.2f}\")\n",
    "    \n",
    "    # Visualize errors\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f'{title} - Error Distribution', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Valence error distribution\n",
    "    axes[0, 0].hist(v_errors, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Valence Error', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 0].set_title(f'Valence Error (MAE: {np.abs(v_errors).mean():.4f})', fontsize=14)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Arousal error distribution\n",
    "    axes[0, 1].hist(a_errors, bins=30, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Arousal Error', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 1].set_title(f'Arousal Error (MAE: {np.abs(a_errors).mean():.4f})', fontsize=14)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Predicted vs True scatter (Valence)\n",
    "    axes[1, 0].scatter(targets[:, 0], predictions[:, 0], alpha=0.5, s=30)\n",
    "    axes[1, 0].plot([1, 9], [1, 9], 'r--', linewidth=2, label='Perfect prediction')\n",
    "    axes[1, 0].set_xlabel('True Valence', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Predicted Valence', fontsize=12)\n",
    "    axes[1, 0].set_title('Valence: Predicted vs True', fontsize=14)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Predicted vs True scatter (Arousal)\n",
    "    axes[1, 1].scatter(targets[:, 1], predictions[:, 1], alpha=0.5, s=30)\n",
    "    axes[1, 1].plot([1, 9], [1, 9], 'r--', linewidth=2, label='Perfect prediction')\n",
    "    axes[1, 1].set_xlabel('True Arousal', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Predicted Arousal', fontsize=12)\n",
    "    axes[1, 1].set_title('Arousal: Predicted vs True', fontsize=14)\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return error_df\n",
    "\n",
    "\n",
    "# Perform error analysis on validation set\n",
    "val_error_df = analyze_predictions(\n",
    "    df=val_df,\n",
    "    predictions=val_preds,\n",
    "    targets=val_targets,\n",
    "    title=\"Validation Set Error Analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7e538",
   "metadata": {},
   "source": [
    "## üíæ Part 19: Download Submission File\n",
    "\n",
    "Download the submission file to submit to CodaBench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b6c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download submission file in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üíæ DOWNLOADING SUBMISSION FILE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    files.download(submission_path)\n",
    "    print(f\"‚úÖ File downloaded: {submission_filename}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è Not running in Google Colab\")\n",
    "    print(f\"üìÅ Submission file saved at: {submission_path}\")\n",
    "    print(f\"üëâ You can manually download it from the outputs folder\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üì§ SUBMISSION INSTRUCTIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. Go to CodaBench: https://www.codabench.org/competitions/10918/\")\n",
    "print(\"2. Navigate to the 'Participate' tab\")\n",
    "print(f\"3. Upload your file: {submission_filename}\")\n",
    "print(\"4. Submit and view results!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457e8078",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéâ NOTEBOOK COMPLETE!\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "### Part 1: Foundation\n",
    "1. ‚úÖ Installed all required packages\n",
    "2. ‚úÖ Loaded and preprocessed data from GitHub\n",
    "3. ‚úÖ Performed comprehensive EDA\n",
    "4. ‚úÖ Created PyTorch Dataset and DataLoaders\n",
    "5. ‚úÖ Built sophisticated VA regression model\n",
    "6. ‚úÖ Defined custom loss function and metrics\n",
    "\n",
    "### Part 2: Training & Evaluation\n",
    "7. ‚úÖ Configured optimizer with layer-wise learning rates\n",
    "8. ‚úÖ Set up learning rate scheduler\n",
    "9. ‚úÖ Trained model with progress tracking\n",
    "10. ‚úÖ Validated and saved best model\n",
    "11. ‚úÖ Visualized training history\n",
    "12. ‚úÖ Generated predictions on test set\n",
    "13. ‚úÖ Created submission file in required format\n",
    "14. ‚úÖ Performed detailed error analysis\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Key Results\n",
    "\n",
    "- **Best Validation RMSE**: Check training output above\n",
    "- **Model**: Transformer-based VA regressor\n",
    "- **Architecture**: Multi-layer regression head with separate V/A outputs\n",
    "- **Features**: Early stopping, gradient clipping, LR scheduling\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "### Improving Performance\n",
    "\n",
    "1. **Try different models**:\n",
    "   ```python\n",
    "   config.model_name = \"xlm-roberta-base\"  # Better for multilingual\n",
    "   config.model_name = \"microsoft/mdeberta-v3-base\"  # State-of-the-art\n",
    "   ```\n",
    "\n",
    "2. **Adjust hyperparameters**:\n",
    "   ```python\n",
    "   config.learning_rate = 3e-5\n",
    "   config.num_epochs = 10\n",
    "   config.batch_size = 32\n",
    "   ```\n",
    "\n",
    "3. **Data augmentation**: Add back-translation or paraphrasing\n",
    "\n",
    "4. **Ensemble**: Train multiple models and average predictions\n",
    "\n",
    "5. **Domain adaptation**: Fine-tune on domain-specific data\n",
    "\n",
    "### Testing Other Languages/Domains\n",
    "\n",
    "Simply change the configuration:\n",
    "```python\n",
    "config.language = \"zho\"  # Chinese\n",
    "config.domain = \"laptop\"  # Laptop reviews\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Competition Resources\n",
    "\n",
    "- **Track A CodaBench**: https://www.codabench.org/competitions/10918/\n",
    "- **GitHub**: https://github.com/DimABSA/DimABSA2026\n",
    "- **Google Group**: https://groups.google.com/g/dimabsa-participants\n",
    "- **Discord**: https://discord.gg/xWXDWtkMzu"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
